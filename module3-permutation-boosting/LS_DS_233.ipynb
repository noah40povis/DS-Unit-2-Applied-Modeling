{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of LS_DS_233.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noah40povis/DS-Unit-2-Applied-Modeling/blob/master/module3-permutation-boosting/LS_DS_233.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U2ha9OWxf0jw"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hTictxWYih7"
      },
      "source": [
        "# Permutation & Boosting\n",
        "\n",
        "- Get **permutation importances** for model interpretation and feature selection\n",
        "- Use xgboost for **gradient boosting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wMejJg0w8v76"
      },
      "source": [
        "### Setup\n",
        "\n",
        "Run the code cell below. You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab.\n",
        "\n",
        "Libraries:\n",
        "\n",
        "- category_encoders\n",
        "- [**eli5**](https://eli5.readthedocs.io/en/latest/)\n",
        "- matplotlib\n",
        "- numpy\n",
        "- pandas\n",
        "- scikit-learn\n",
        "- [**xgboost**](https://xgboost.readthedocs.io/en/latest/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFQMky3CYih-",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install eli5\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUjuINMytgNE",
        "colab_type": "text"
      },
      "source": [
        "We'll go back to Tanzania Waterpumps for this lesson."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z-TExplb_Slf",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rhg8PQKt_jzP",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'status_group'\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "X_test = test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m8lB4z5l_eml",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=20, \n",
        "                           random_state=42, \n",
        "                           n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTZlJ3AxP4g0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "05bd5c9b-c6d0-42af-b82f-9c555985bf87"
      },
      "source": [
        "print('Training Accuracy:', pipeline.score(X_train, y_train))\n",
        "print('Validation Accuracy:', pipeline.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9956439393939394\n",
            "Validation Accuracy: 0.8014309764309764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX08z7xNJEcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "f4cc1b40-9960-4db7-9250-653271ab4ae6"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    GradientBoostingClassifier(random_state=42)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3799d0448601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Fit on train, score on val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1439\u001b[0m         \u001b[0;31m# Since check_array converts both X and y to the same dtype, but the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# trees use different types for X and y, checking them separately.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8ELxIIUJeDM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2d509ef7-2ef0-4cd7-faa9-11eb8df474eb"
      },
      "source": [
        "print('Training Accuracy:', pipeline.score(X_train, y_train))\n",
        "print('Validation Accuracy:', pipeline.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.7591540404040404\n",
            "Validation Accuracy: 0.7547138047138047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAc-HQtcKcXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "3ca8849e-77bd-472f-a37c-6235c5e4eed7"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    XGBClassifier(n_estimators=100,\n",
        "                  random_state=42,\n",
        "                  n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['funder', 'installer', 'wpt_name',\n",
              "                                      'basin', 'subvillage', 'region', 'lga',\n",
              "                                      'ward', 'public_meeting',\n",
              "                                      'scheme_management', 'scheme_name',\n",
              "                                      'permit', 'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'management_group', 'payment',\n",
              "                                      'water_quality', 'quality_group',\n",
              "                                      'quantit...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=42,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBEPtvbGLHFz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "52a0ad0e-f1e6-48ed-c433-ae1193ae3f80"
      },
      "source": [
        "print('Training Accuracy:', pipeline.score(X_train, y_train))\n",
        "print('Validation Accuracy:', pipeline.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.7511153198653199\n",
            "Validation Accuracy: 0.7466329966329966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XezGwAd0tgNO",
        "colab_type": "text"
      },
      "source": [
        "# Get permutation importances for model interpretation and feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV_Ebu4WtgNO",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Deg7mJ-otgNP",
        "colab_type": "text"
      },
      "source": [
        "Default Feature Importances are fast, but Permutation Importances may be more accurate.\n",
        "\n",
        "These links go deeper with explanations and examples:\n",
        "\n",
        "- Permutation Importances\n",
        "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "- (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7HOayKBOYiit"
      },
      "source": [
        "There are three types of feature importances:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4bRhsxENYiiu"
      },
      "source": [
        "### 1. (Default) Feature Importances\n",
        "\n",
        "Fastest, good for first estimates, but be aware:\n",
        "\n",
        "\n",
        "\n",
        ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable. — [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
        "\n",
        "\n",
        " \n",
        " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.” —  [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BNVm6f7mYiiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "outputId": "9c42de82-c25b-419e-c63e-d5ce007b6028"
      },
      "source": [
        "# Get feature importances\n",
        "rf = pipeline.named_steps['randomforestclassifier']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "\n",
        "# Plot feature importances\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 30\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='grey');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y8HzLcCBYiiv"
      },
      "source": [
        "### 2. Drop-Column Importance\n",
        "\n",
        "The best in theory, but too slow in practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NagDf1ERMWc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ad734794-b3ef-4e56-850e-828e5663fd2e"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47520, 45)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQAOlERnYiiw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "854e690b-e4f5-4744-9b1b-17ff20f8b5cc"
      },
      "source": [
        "column  = 'quantity'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=20, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Fit with column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=20, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train, y_train)\n",
        "score_with = pipeline.score(X_val, y_val)\n",
        "print(f'Validation Accuracy with {column}: {score_with}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without quantity: 0.7674242424242425\n",
            "Validation Accuracy with quantity: 0.8014309764309764\n",
            "Drop-Column Importance for quantity: 0.03400673400673393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Vu39wGkYiix"
      },
      "source": [
        "### 3. Permutation Importance\n",
        "\n",
        "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
        "\n",
        "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
        "\n",
        "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
        ">\n",
        "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
        ">\n",
        ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
        ">\n",
        ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GYCiEx7zYiiy"
      },
      "source": [
        "### Do-It-Yourself way, for intuition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TksOf_n2Yiiy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "a90a82eb-8708-461d-c54a-9fd5d8c49fcc"
      },
      "source": [
        "# Step 1: Train your model\n",
        "# See above\n",
        "\n",
        "# Step 2: Shuffle the values in a single column (one feature)\n",
        "# OF YOUR VALIDATION SET\n",
        "feature = 'quantity'\n",
        "print(X_val[feature].head())\n",
        "print()\n",
        "print(X_val[feature].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3290     insufficient\n",
            "47666    insufficient\n",
            "2538           enough\n",
            "53117          enough\n",
            "51817          enough\n",
            "Name: quantity, dtype: object\n",
            "\n",
            "enough          6619\n",
            "insufficient    2976\n",
            "dry             1325\n",
            "seasonal         806\n",
            "unknown          154\n",
            "Name: quantity, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeCFW8CQS6Em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val_permuted[feature])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CakBx-wPT3uy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "84d98938-72a3-4431-ac0e-7deb2c19ef99"
      },
      "source": [
        "acc = pipeline.score(X_val, y_val)\n",
        "acc_permuted = pipeline.score(X_val_permuted, y_val)\n",
        "\n",
        "print(f'Validation accuracy with {feature}:', acc)\n",
        "print(f'Validation accuracy with {feature} permuted:', acc_permuted)\n",
        "print(f'Permutation importance:', acc - acc_permuted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy with quantity: 0.8014309764309764\n",
            "Validation accuracy with quantity permuted: 0.6951178451178451\n",
            "Permutation importance: 0.10631313131313125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LYk19SNYii7"
      },
      "source": [
        "### With eli5 library\n",
        "\n",
        "For more documentation on using this library, see:\n",
        "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
        "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
        "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
        "\n",
        "eli5 doesn't work with pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hpSemTkFFP8i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "4f73f70a-789a-49d6-cbde-dfe7469b54b9"
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "# Ignore warnings\n",
        "\n",
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median')\n",
        ")\n",
        "\n",
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.transform(X_val)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=20, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train_transformed, y_train)\n",
        "\n",
        "\n",
        "\n",
        "feature_names = X_val.columns.tolist()\n",
        "\n",
        "permuter = PermutationImportance(\n",
        "    model,\n",
        "    scoring='accuracy',\n",
        "    n_iter=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_transformed, y_val)\n",
        "\n",
        "eli5.show_weights(\n",
        "    permuter,\n",
        "    top=None,\n",
        "    feature_names=feature_names\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1055\n",
              "                \n",
              "                    &plusmn; 0.0037\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.16%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0182\n",
              "                \n",
              "                    &plusmn; 0.0036\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.04%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0144\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.67%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0119\n",
              "                \n",
              "                    &plusmn; 0.0026\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                amount_tsh\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.54%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0086\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.59%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0084\n",
              "                \n",
              "                    &plusmn; 0.0021\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.72%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0080\n",
              "                \n",
              "                    &plusmn; 0.0037\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.85%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0075\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0058\n",
              "                \n",
              "                    &plusmn; 0.0031\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.70%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0048\n",
              "                \n",
              "                    &plusmn; 0.0023\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                payment\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.76%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0046\n",
              "                \n",
              "                    &plusmn; 0.0022\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.96%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0040\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.29%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0031\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ward\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.29%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0031\n",
              "                \n",
              "                    &plusmn; 0.0026\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.48%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0027\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                funder\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.51%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0026\n",
              "                \n",
              "                    &plusmn; 0.0019\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.55%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0025\n",
              "                \n",
              "                    &plusmn; 0.0027\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.56%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0025\n",
              "                \n",
              "                    &plusmn; 0.0025\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.87%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0017\n",
              "                \n",
              "                    &plusmn; 0.0022\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                day_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.01%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0014\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                district_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.02%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0014\n",
              "                \n",
              "                    &plusmn; 0.0027\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                month_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.03%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0014\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                subvillage\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.04%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0014\n",
              "                \n",
              "                    &plusmn; 0.0027\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.11%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0012\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.20%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.21%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0010\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                year_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.24%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0010\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                installer\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                public_meeting\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.41%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                permit\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.41%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0017\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.43%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.45%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.56%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0019\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                wpt_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.76%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.93%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                lga\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.93%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.96%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                water_quality\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.85%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0001\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quality_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.78%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.59%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0004\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                basin\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.47%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0006\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                num_private\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.39%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0007\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATjDE9ACYFHR",
        "colab_type": "text"
      },
      "source": [
        "## Permutation Importance in `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wk6xx31YJQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "pi = permutation_importance(pipeline,\n",
        "                            X_val,\n",
        "                            y_val,\n",
        "                            random_state=42,\n",
        "                            n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8ph1tXVYUg6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6825b599-3059-4d9c-bfb4-a1e6f78c2d45"
      },
      "source": [
        "pi.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['importances_mean', 'importances_std', 'importances'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qJR1_kjYvZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "821b8a03-aa13-4ba0-fd67-ceb10d3dcfd7"
      },
      "source": [
        "p_importance = pd.DataFrame({'feature' : X_val.columns,\n",
        "                             'weight'  : pi.importances_mean,\n",
        "                             'std'     : pi.importances_std})\n",
        "\n",
        "p_importance.sort_values('weight', ascending=False).tail(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>weight</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>installer</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>quality_group</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.000531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>water_quality</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.000798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>region</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>0.000478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>construction_year_MISSING</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>latitude_MISSING</td>\n",
              "      <td>-0.000067</td>\n",
              "      <td>0.000163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>year_recorded</td>\n",
              "      <td>-0.000168</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>num_private</td>\n",
              "      <td>-0.000505</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>basin</td>\n",
              "      <td>-0.000572</td>\n",
              "      <td>0.000817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>population_MISSING</td>\n",
              "      <td>-0.000589</td>\n",
              "      <td>0.000873</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      feature    weight       std\n",
              "3                   installer  0.000337  0.000804\n",
              "28              quality_group  0.000219  0.000531\n",
              "27              water_quality  0.000219  0.000798\n",
              "10                     region  0.000118  0.000478\n",
              "37  construction_year_MISSING  0.000067  0.000520\n",
              "36           latitude_MISSING -0.000067  0.000163\n",
              "40              year_recorded -0.000168  0.000894\n",
              "7                 num_private -0.000505  0.000000\n",
              "8                       basin -0.000572  0.000817\n",
              "39         population_MISSING -0.000589  0.000873"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q07yW9k-Yii8"
      },
      "source": [
        "### We can use importances for feature selection\n",
        "\n",
        "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZrPFyEMYii9",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fl67bCR7WY6j"
      },
      "source": [
        "# Use xgboost for gradient boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIaF7BpUtgNj",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f4-hD58tgNj",
        "colab_type": "text"
      },
      "source": [
        "In the Random Forest lesson, you learned this advice:\n",
        "\n",
        "#### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
        "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
        "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
        "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
        "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
        "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6y-QHCctgNk",
        "colab_type": "text"
      },
      "source": [
        "Like Random Forest, Gradient Boosting uses ensembles of trees. But the details of the ensembling technique are different:\n",
        "\n",
        "### Understand the difference between boosting & bagging\n",
        "\n",
        "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
        "\n",
        "Here's an excerpt from [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
        "\n",
        ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
        ">\n",
        ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
        ">\n",
        ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
        ">\n",
        ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
        ">\n",
        ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown.\n",
        "\n",
        "This high-level overview is all you need to know for now. If you want to go deeper, we recommend you watch the StatQuest videos on gradient boosting!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK7BnrV4tgNk",
        "colab_type": "text"
      },
      "source": [
        "Let's write some code. We have lots of options for which libraries to use:\n",
        "\n",
        "#### Python libraries for Gradient Boosting\n",
        "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
        "  - Anaconda: already installed\n",
        "  - Google Colab: already installed\n",
        "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
        "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
        "  - Windows: `conda install -c anaconda py-xgboost`\n",
        "  - Google Colab: already installed\n",
        "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
        "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
        "  - Google Colab: already installed\n",
        "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
        "  - Anaconda: `conda install -c conda-forge catboost`\n",
        "  - Google Colab: `pip install catboost`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMEiSt13tgNl",
        "colab_type": "text"
      },
      "source": [
        "In this lesson, you'll use a new library, xgboost — But it has an API that's almost the same as scikit-learn, so it won't be a hard adjustment!\n",
        "\n",
        "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wsnJRKjfWYph",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eCjVSlD_XJr2"
      },
      "source": [
        "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
        "\n",
        "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
        "\n",
        "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
        "\n",
        "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
        "\n",
        "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
        "\n",
        "#### XGBoost parameters\n",
        "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
        "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNX3IKftXBFS",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZF7-ml6BhRRf"
      },
      "source": [
        "### Try adjusting these hyperparameters\n",
        "\n",
        "#### Random Forest\n",
        "- class_weight (for imbalanced classes)\n",
        "- max_depth (usually high, can try decreasing)\n",
        "- n_estimators (too low underfits, too high wastes time)\n",
        "- min_samples_leaf (increase if overfitting)\n",
        "- max_features (decrease for more diverse trees)\n",
        "\n",
        "#### Xgboost\n",
        "- scale_pos_weight (for imbalanced classes)\n",
        "- max_depth (usually low, can try increasing)\n",
        "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
        "- learning_rate (too low underfits, too high overfits)\n",
        "\n",
        "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8WB8657tgNs",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint. Complete these tasks for your project, and document your work.\n",
        "\n",
        "- Continue to clean and explore your data. Make exploratory visualizations.\n",
        "- Fit a model. Does it beat your baseline?\n",
        "- Try xgboost.\n",
        "- Get your model's permutation importances.\n",
        "\n",
        "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
        "\n",
        "But, if you aren't ready to try xgboost and permutation importances with your dataset today, you can practice with another dataset instead. You may choose any dataset you've worked with previously."
      ]
    }
  ]
}